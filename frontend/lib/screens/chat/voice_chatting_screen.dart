// Dart imports:
import 'dart:async';

// Flutter imports:
import 'package:flutter/material.dart';

// Package imports:
import 'package:flutter_tts/flutter_tts.dart';
import 'package:noise_meter/noise_meter.dart';
import 'package:permission_handler/permission_handler.dart';
import 'package:speech_to_text/speech_to_text.dart' as stt;
import 'package:audioplayers/audioplayers.dart';
import 'package:flutter_dotenv/flutter_dotenv.dart';


// Project imports:
import 'package:buds/config/theme.dart';
import 'package:buds/services/chat_service.dart';

class VoiceChattingScreen extends StatefulWidget {
  const VoiceChattingScreen({super.key});

  @override
  State<VoiceChattingScreen> createState() => _VoiceChattingScreenState();
}

class _VoiceChattingScreenState extends State<VoiceChattingScreen> {
  final stt.SpeechToText _speech = stt.SpeechToText();
  final FlutterTts _tts = FlutterTts();
  final ChatService _chatService = ChatService();
  final int userId = 4;

  bool _isMuted = false;
  bool _ttsPlaying = false;

  List<Map<String, dynamic>> _chatHistory = [];

  late NoiseMeter _noiseMeter;
  StreamSubscription<NoiseReading>? _noiseSubscription;
  final ScrollController _scrollController = ScrollController();

  @override
  void initState() {
    super.initState();
    _initializeTTS();
    _initializeSTT();
    _checkMicPermission();
  }

  void _initializeTTS() async {
    await _tts.setLanguage("ko-KR");
    await _tts.setSpeechRate(0.45);
    await _tts.setPitch(1.0);
    await _tts.setVolume(1.0);

    _tts.setStartHandler(() {
      _ttsPlaying = true;
      _stopListening();
      _startNoiseListener();
    });

    _tts.setCompletionHandler(() {
      _ttsPlaying = false;
      _noiseSubscription?.cancel();
      _noiseSubscription = null;
      if (!_isMuted) _startListening();
    });
  }

  Future<void> _playRemoteAudio(String audioPath) async {
    final baseUrl = dotenv.env['FASTAPI_URL'];
    if (baseUrl == null || baseUrl.isEmpty) {
      print('âŒ FASTAPI_URL ëˆ„ë½');
      return;
    }

    final url = '$baseUrl$audioPath';
    print('ğŸ”Š ì¬ìƒí•  URL: $url');

    try {
      final player = AudioPlayer();

      // ğŸ” ì¬ìƒ ìƒíƒœ ë¨¼ì € listen() ë“±ë¡
      player.onPlayerStateChanged.listen((state) {
        print('ğŸ§ í˜„ì¬ ìƒíƒœ: $state');
      });

      // ğŸ”Š ì„¤ì •
      await player.setReleaseMode(ReleaseMode.stop);
      await player.setVolume(1.0);

      // â–¶ï¸ ì¬ìƒ ì‹œë„
      print('ğŸ“¢ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œë„ ì „');
      await player.play(UrlSource(url));
      print('ğŸ“¢ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œë„ í›„');
    } catch (e) {
      print('âŒ ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜: $e');
    }
  }

  Future<void> _checkMicPermission() async {
    final status = await Permission.microphone.status;

    if (!status.isGranted) {
      final result = await Permission.microphone.request();
      if (result.isGranted) {
        print('ğŸ¤ ë§ˆì´í¬ ê¶Œí•œ í—ˆìš©ë¨');
        _initializeSTT();
      } else {
        print('âŒ ë§ˆì´í¬ ê¶Œí•œ ê±°ë¶€ë¨');
        if (mounted) {
          ScaffoldMessenger.of(context).showSnackBar(
            const SnackBar(content: Text('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤')),
          );
        }
      }
    } else {
      print('âœ… ë§ˆì´í¬ ê¶Œí•œ ì´ë¯¸ ìˆìŒ');
      _initializeSTT();
    }
  }

  void _initializeSTT() async {
    final available = await _speech.initialize(
      onStatus: (status) => print('ğŸ™ï¸ STT ìƒíƒœ: $status'),
      onError: (error) => print('âŒ STT ì˜¤ë¥˜: $error'),
    );

    print('âœ… STT ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€: $available');
    if (available) {
      _startListening();
    } else {
      print('ğŸš« STT ì´ˆê¸°í™” ì‹¤íŒ¨: ë§ˆì´í¬ ê¶Œí•œ í™•ì¸ í•„ìš”');
    }
  }

  Future<void> _startListening() async {
    await Future.delayed(const Duration(milliseconds: 200));

    if (_speech.isListening || _isMuted || _ttsPlaying) return;

    final initialized = await _speech.initialize(
      onStatus: (status) {
        print('ğŸ™ï¸ STT ìƒíƒœ: $status');
        if (status == 'done' || status == 'notListening') {
          Future.delayed(const Duration(milliseconds: 500), _startListening);
        }
      },
      onError: (error) {
        print('âŒ STT ì˜¤ë¥˜: $error');
        if (error.permanent || error.errorMsg == 'error_speech_timeout') {
          Future.delayed(const Duration(milliseconds: 500), _startListening);
        }
      },
    );

    if (initialized) {
      print("âœ… STT ì‹œì‘");
      _speech.listen(
        onResult: (result) {
          print("ğŸ§ onResult called!");
          print("ğŸ‘‰ ì¸ì‹ëœ ë¬¸ì¥: '${result.recognizedWords}'");
          print("âœ… FinalResult ì—¬ë¶€: ${result.finalResult}");

          if (result.finalResult && result.recognizedWords.trim().isNotEmpty) {
            _handleUserSpeech(result.recognizedWords.trim());
          }
        },
        listenFor: const Duration(seconds: 30),
        pauseFor: const Duration(seconds: 5),
        localeId: 'ko_KR',
        listenOptions: stt.SpeechListenOptions(
          listenMode: stt.ListenMode.dictation,
          partialResults: true,
          cancelOnError: true,
        ),
      );
    } else {
      print("âŒ STT ì´ˆê¸°í™” ì‹¤íŒ¨");
    }
  }

  void _stopListening() {
    if (_speech.isListening) {
      _speech.stop();
    }
  }

  void _startNoiseListener() {
    if (_noiseSubscription != null) return;

    _noiseMeter = NoiseMeter();

    try {
      _noiseSubscription = _noiseMeter.noise.listen((NoiseReading reading) {
        final dB = reading.meanDecibel;
        print("ğŸ“ˆ í˜„ì¬ ì†ŒìŒ dB: $dB");

        if (_ttsPlaying && dB > 94) {
          print("ğŸ¤ ì‚¬ìš©ì ë§ ê°ì§€ë¨! â†’ TTS ì¤‘ë‹¨ â†’ STT ì‹œì‘");

          _tts.stop();
          _ttsPlaying = false;

          _noiseSubscription?.cancel();
          _noiseSubscription = null;

          if (_speech.isListening) _speech.stop();
          Future.delayed(const Duration(milliseconds: 300), _startListening);
        }
      });
    } catch (e) {
      print("âŒ NoiseMeter ì˜¤ë¥˜: $e");
    }
  }

  void _handleUserSpeech(String text) async {
    setState(() {
      _chatHistory.add({"text": text, "isUser": true});
    });

    WidgetsBinding.instance.addPostFrameCallback((_) {
      _scrollController.jumpTo(_scrollController.position.maxScrollExtent);
    });

    try {
      final response = await _chatService.sendMessage(
        message: text,
        isVoice: true,
      );

      final messageText = response['text'];
      final audioPath = response['audioPath'];

      setState(() {
        _chatHistory.add({"text": messageText, "isUser": false});
      });

      WidgetsBinding.instance.addPostFrameCallback((_) {
        _scrollController.jumpTo(_scrollController.position.maxScrollExtent);
      });

      if (!_isMuted && audioPath != null) {
        Future.delayed(const Duration(milliseconds: 500), () {
          _playRemoteAudio(audioPath);
        });
      } else if (!_isMuted) {
        await _tts.speak(messageText);
      } else {
        _startListening();
      }
    } catch (e) {
      print("âŒ ì˜¤ë¥˜: $e");
      _startListening();
    }
  }

  void _toggleMute() {
    setState(() => _isMuted = !_isMuted);

    if (_isMuted) {
      _tts.stop();
      _speech.stop();
      _noiseSubscription?.cancel();
      _noiseSubscription = null;
    } else {
      Future.delayed(const Duration(milliseconds: 300), () {
        if (!_speech.isListening) {
          _startListening();
        }
      });
    }
  }

  @override
  void dispose() {
    _noiseSubscription?.cancel();
    _speech.stop();
    _tts.stop();
    _scrollController.dispose();
    super.dispose();
  }

  @override
  Widget build(BuildContext context) {
    final screenHeight = MediaQuery.of(context).size.height;
    final screenWidth = MediaQuery.of(context).size.width;

    return Scaffold(
      backgroundColor: AppColors.cardBackground,
      body: SafeArea(
        child: Column(
          children: [
            SizedBox(height: screenHeight * 0.08),
            Image.asset('assets/images/marmet_head.png', width: screenHeight * 0.25),
            const SizedBox(height: 16),
            Expanded(
              child: ListView.builder(
                controller: _scrollController,
                padding: const EdgeInsets.all(16),
                itemCount: _chatHistory.length,
                itemBuilder: (context, index) {
                  final chat = _chatHistory[index];
                  return Align(
                    alignment: chat['isUser'] ? Alignment.centerRight : Alignment.centerLeft,
                    child: Container(
                      margin: const EdgeInsets.symmetric(vertical: 6),
                      padding: const EdgeInsets.symmetric(vertical: 10, horizontal: 14),
                      decoration: BoxDecoration(
                        color: chat['isUser'] ? const Color(0xfffef1d3) : Colors.grey.shade200,
                        borderRadius: BorderRadius.circular(12),
                      ),
                      child: Text(chat['text'] ?? '', style: const TextStyle(fontSize: 15)),
                    ),
                  );
                },
              ),
            ),
            Padding(
              padding: EdgeInsets.only(bottom: screenHeight * 0.04),
              child: Row(
                mainAxisAlignment: MainAxisAlignment.spaceAround,
                children: [
                  GestureDetector(
                    onTap: _toggleMute,
                    child: Image.asset(
                      _isMuted ? 'assets/icons/mic_off.png' : 'assets/icons/mic_on.png',
                      width: screenWidth * 0.1,
                    ),
                  ),
                  GestureDetector(
                    onTap: () {
                      _tts.stop();
                      _speech.stop();
                      _noiseSubscription?.cancel();
                      Navigator.pop(context);
                    },
                    child: const Icon(Icons.close, size: 40, color: Colors.black),
                  ),
                ],
              ),
            ),
          ],
        ),
      ),
    );
  }
}
